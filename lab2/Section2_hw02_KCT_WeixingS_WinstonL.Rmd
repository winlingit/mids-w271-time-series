---
title: "Lab 2"
author: "K.C. Tobin"
date: "June 29, 2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#knitr::opts_knit$set(root.dir = "C:/Users/kctob/OneDrive/Documents/Berkeley/271/mids-w271-time-series/lab2")
library(car)
library(stargazer)
library(Hmisc)
library(effects)
```

# The Lab
  
  - Even though it is not included in these questions, conduct a comprehensive Exploratory Data Analysis (EDA) analysis, which includes both graphical and tabular analysis, as taught in this course.

    - According to online information of this study,
    - Color = female crab’s color (1,2,3,4; 1=lightest to 4=darkest)
    - Spine = female crab’s spine condition (1 = both good, 2= one worn or broken, 3=both worn or broken)
    - Width = female crab’s carapace width (cm)
    - Weight = female crab’s weight (kg)


```{r, warning=FALSE}
hs <- read.csv("HorseshoeCrabs.csv")
hs$Color.cat <- factor(hs$Color, labels = c("very light", "light", "dark", "very dark"))
hs$Spine.cat <- factor(hs$Spine, labels = c("2 good", "1 good", "0 good"))
scatterplotMatrix(hs[c(3,4,5)])
```
- Insights from scatterplots: 1. width and weight has a clear positive linear correlation, which makes sense since a heavier horse shoe crab should be wider; 2. Sat shows a frequency distribution that might be fitted by poisson model.
```{r}
xtabs(~Color.cat + Spine.cat, data = hs)
boxplot(hs$Sat~hs$Color.cat)
boxplot(hs$Sat~hs$Spine.cat)
```
- Insights from the contigency table and boxplots: 1. width and weight has a clear positive linear correlation, which makes sense since a heavier horse shoe crab should be wider; 2. Sat shows a frequency distribution that might be fitted by poisson model.

23. Agresti (2007) provides data on the social behavior of horshoe crabs. These data are contained in hte HorseshoesCrabs.csv file available on our website. Each observation corresponds to one female crab. The response variable is Sat, the number of "satellite" males in her vicinity. Physical measurements of the female - Color (4-level ordinal), Spine (3-level ordinal), Width (cm), and Weight (kg) - are explanatory variables.
  
    a) Fit a Poisson regression model with a log link using all four explanatory variables in a linear form. Test their significance and summarize results.
    
```{r}
# Poisson with ordinal variables
mod1 <- glm(Sat ~ Color + Spine + Width + Weight, family = poisson(link="log"), data=hs)
summary(mod1)
Anova(mod1)
```

  - Results show that only Color and Weight parameters are statistically significant. LRT also shows strong evidence that the effect of color and weight are statistically significant (p-value < 0.05).

```{r}
# Poisson with categorical variables
mod2 <- glm(Sat ~ Color.cat + Spine.cat + Width + Weight, family = poisson(link="log"), data=hs)
summary(mod2)
Anova(mod2)
```

  - Next, we transform Color and Spine to categorical variables to run Poisson fitting again. It shows similar results with mod1. However, it is noticable that only dark colors (3 & 4) show a significant effect on satellites.

b) Compute deviance/df and interpret its value.
```{r}
# calculate residual deviance of Color in mod1
mod1.1 = glm(Sat ~ Spine + Width + Weight, family = poisson(link="log"), data=hs)
anova(mod1.1, mod1, test = "Chisq")
# calculate residual deviance of Weight in mod1
mod1.2 = glm(Sat ~ Color + Spine + Width, family = poisson(link="log"), data=hs)
anova(mod1.2, mod1, test = "Chisq")
# calculate residual deviance of Color in mod2
mod2.1 = glm(Sat ~ Spine.cat + Width + Weight, family = poisson(link="log"), data=hs)
anova(mod2.1, mod2, test = "Chisq")
# calculate residual deviance of Weight in mod2
mod2.2 = glm(Sat ~ Color.cat + Spine.cat + Width, family = poisson(link="log"), data=hs)
anova(mod2.2, mod2, test = "Chisq")


###  deviance/df calculations from p.293

# # null model
# glm.Ho = glm(formula = Sat ~ 1, family = poisson(link = 'log'), data = dt)
# summary(glm.Ho)
# 
# # LRT to calculate deviance and df
# lrt = anova(glm.Ho, glm.Ha, test = 'Chisq')
# dev.df = lrt$`Resid. Dev`/lrt$`Resid. Df`
# dev.df[2]
# 
# t1 = 1 + 2*sqrt(2/lrt$`Resid. Dev`[2])
# t1
# 
# t2 = 1 + 3*sqrt(2/lrt$`Resid. Dev`[2])
# t2
```    
  - Need more explanations on residual deviance!!!!!!   
   
    c) Examine residual diagnostics and identify any potential problems with the model.
```{r, warning=FALSE}
plot(allEffects(mod2))
residualPlots(mod2)

### plots of working residuals

# # residual plots
# summary(glm.Ha$residuals)
# plot(glm.Ha$residuals)
# hist(glm.Ha$residuals)
# qqnorm(glm.Ha$residuals)
```
  - Need more explanations on residual diagnostics!!!!!!   
  
    d) Carry out the GOF test described on page 296 using the PostFitGOFTest() function available in the PostFitGOFTest.R program of the same name from our website. Use the default number of groups. (M/5 when M < 100)
        i. State the hypotheses, test statistic and p-value, and interpret the results.
        
        The hypothesis is the observed residuals of our model predictions for the 20 quantiles is not significantly different from the predictions thus indicating a good model fit. The GOF test gives us a test statistic of 776.2152 which is the total Pearson residuals at our 20 quantiles. This test statistic gives a p-value of effectively 0 on chi-squared distribution with 18 degrees of freedom indicating there is some evidence that our model is not well fit. This evidence support previous graphical analysis already conducted above.
        
        ii. Plot the Pearson residuals for the groups against the interval centers (availabe in the pear.res and centers components, respectively, of the list returned by the function). Use this plot and the resiudal plots from part (c) to explain the results.
        
        As you can see in the plot below the Pearson residuals for out 20 quantiles range quite drastically from just below 0 to over 8. These residuals are much higher than we would expect if our model was an accurate representation of the data. In addition you can see the model is not consistent and the residuals vary based on predicted values.
        
```{r}

PostFitGOFTest = function(obs, pred, g = 0) {
  if(g == 0) g = round(min(length(obs)/5,20))
  ord <- order(pred)
  obs.o <- obs[ord]
  pred.o <- pred[ord]
  interval = cut(pred.o, quantile(pred.o, 0:g/g), include.lowest = TRUE)  
  # Creates factor with levels 1,2,...,g
  counts = xtabs(formula = cbind(obs.o, pred.o) ~ interval)
  centers <- aggregate(formula = pred.o ~ interval, FUN = "mean")
  pear.res <- rep(NA,g)
  for(gg in (1:g)) pear.res[gg] <- (counts[gg] - counts[g+gg])/sqrt(counts[g+gg])
  pearson <- sum(pear.res^2)
  if (any(counts[((g+1):(2*g))] < 5))
  warning("Some expected counts are less than 5. Use smaller number of groups")
  P = 1 - pchisq(pearson, g - 2)
  cat("Post-Fit Goodness-of-Fit test with", g, "bins", "\n", 
      "Pearson Stat = ", pearson, "\n", "p = ", P, "\n")
  return(list(pearson = pearson, pval = P, centers = centers$pred.o, observed = counts[1:g], 
              expected = counts[(g+1):(2*g)], pear.res = pear.res))
}

preds <- predict(mod1, hs)
obs <- hs$Sat
results <- PostFitGOFTest(obs,preds)
results

plot(results$pear.res~results$centers)

# # run GOF test
# gof.test = PostFitGOFTest(dt$Sat, glm.Ha$fitted.values)

# # scatterplots for Pearson residuals and interval centers
# df = data.frame(cbind(pear.res = gof.test$pear.res, centers = gof.test$centers))
# plt2 = ggplot(df, aes(x = pear.res, y = centers))
# plt2 + geom_point() + labs(title = 'Horseshoe Crab Data', x = 'Pearson residual', y = 'Interval center')
```
  
24. Conduct an influence analysis. Interpret the results.

```{r}
plot(mod1)[4]
plot(mod2)[4]

glmInflDiag <- function(mod.fit, print.output = TRUE, which.plots = c(1,2)){

 # Which set of plots to show
 show <- rep(FALSE, 2)  # Idea from plot.lm()
 show[which.plots] <- TRUE

 # Main quantities: Pearson and deviance residual, model Pearson and deviance stats
 pear <- residuals(mod.fit, type = "pearson")
 dres <- residuals(mod.fit, type = "deviance")
 x2 <- sum(pear^2)
 N <- length(pear)
 P <- length(coef(mod.fit))
 # Hat values (leverages)
 hii <- hatvalues(mod.fit)
 # Computed quantities: Standardized Pearson residual, Delta-beta, Delta-deviance
 sres <- pear/sqrt(1-hii)
# D.beta <- (pear^2*hii/(1-hii)^2)
# cookD <- D.beta / (P * summary(mod.fit)$dispersion)
 cookD <- pear^2 * hii / ((1-hii)^2 * (P) * summary(mod.fit)$dispersion) 
 D.dev2 <- dres^2 + hii*sres^2
 D.X2 <- sres^2

 yhat <- fitted(mod.fit)

 # Plots against fitted values 
 if(show[1] == TRUE) {
  x11(height = 7,width = 15, pointsize = 15)
  par(mfrow = c(1,4), lty = "dotted")
  plot(x = yhat, y = hii, xlab = "Estimated Mean or Probability", ylab = "Hat (leverage) value",
   ylim = c(0, max(hii,3*P/N)))
  abline(h = c(2*P/N,3*P/N))

  plot(x = yhat, y = D.X2, xlab = "Estimated Mean or Probability", ylab = "Approx change in Pearson stat",
   ylim = c(0, max(D.X2,9)))
  abline(h = c(4,9), lty = "dotted")

  plot(x = yhat, y = D.dev2, xlab = "Estimated Mean or Probability", ylab = "Approx change in deviance",
   ylim = c(0, max(D.dev2,9)))
  abline(h = c(4,9), lty = "dotted")

  plot(x = yhat, y = cookD, xlab = "Estimated Mean or Probability", ylab = "Approx Cook's Distance",
   ylim = c(0, max(cookD, 1)))
  abline(h = c(4/N,1), lty = "dotted")
 }
 
 # Plots against hat values
 if(show[2] == TRUE) {
  x11(height = 6, width = 12, pointsize = 20)
  par(mfrow = c(1,3))
  plot(x = hii, y = D.X2, xlab = "Hat (leverage) value", ylab = "Approx change in Pearson stat",
   ylim = c(0, max(D.X2, 9)), xlim = c(0, max(hii,3*P/N)))
  abline(h = c(4,9), lty = "dotted")
  abline(v = c(2*P/N,3*P/N), lty = "dotted")

  plot(x = hii, y = D.dev2, xlab = "Hat (leverage) value", ylab = "Approx change in deviance",
   ylim = c(0, max(D.dev2,9)), xlim = c(0, max(hii,3*P/N)))
  abline(h = c(4,9), lty = "dotted")
  abline(v = c(2*P/N,3*P/N), lty = "dotted")

  plot(x = hii, y = cookD, xlab = "Hat (leverage) value", ylab = "Approx Cook's Distance",
   ylim = c(0, max(cookD, 1)), xlim = c(0, max(hii,3*P/N)))
  abline(h = c(4/N,1), lty = "dotted")
  abline(v = c(2*P/N,3*P/N), lty = "dotted")
 }

 # Listing of values to check
 # Create flags to identify high values in listing
 hflag <- ifelse(test = hii > 3*P/N, yes = "**", no = 
          ifelse(test = hii > 2*P/N, yes = "*", no = ""))
 xflag <- ifelse(test = D.X2 > 9, yes = "**", no = 
          ifelse(test = D.X2 > 4, yes = "*", no = ""))
 dflag <- ifelse(test = D.dev2 > 9, yes = "**", no = 
          ifelse(test = D.dev2 > 4, yes = "*", no = ""))
 cflag <- ifelse(test = cookD > 1, yes = "**", no = 
          ifelse(test = cookD > 4/N, yes = "*", no = ""))

 chk.hii2 <- which(hii > 3*P/N)
 chk.DX22 <- which(D.X2 > 9 | (D.X2 > 4 & hii > 2*P/N))
 chk.Ddev2 <- which(D.dev2 > 9 | (D.dev2 > 4 & hii > 2*P/N))
 chk.cook2 <- which(cookD > 4/N)

 all.meas <- data.frame(h = round(hii,2), hflag, Del.X2 = round(D.X2,2), xflag,
             Del.dev = round(D.dev2,2), dflag, Cooks.D = round(cookD,3), cflag)

 if(print.output == TRUE) {
  cat("Potentially influential observations by any measures","\n")
  print(all.meas[sort(unique(c(chk.hii2, chk.DX22, chk.Ddev2, chk.cook2))),])
  cat("\n","Data for potentially influential observations","\n")
  print(cbind(mod.fit$data, yhat = round(yhat, 3))[sort(unique(c(chk.hii2, chk.DX22, chk.Ddev2, chk.cook2))),])
 }

 data.frame(hat  =  hii, CD = cookD, delta.Xsq = D.X2, delta.D = D.dev2)
}

glmInflDiag(mod2, print.output = TRUE, which.plots = 1:2)
```

25. Remove the influential crab from the analysis and repeat the steps in Question 23. Has this fixed the problems with the model? Are there any other problems with the model, and what could be done to solve these problems?

```{r}
hs2 <- hs[-165,]
mod2 <- glm(Sat~Color+Spine+Width+Weight, family = poisson(link="log"), data=hs2)
summary(mod2)
Anova(mod2)
stargazer(mod1,mod2,type="text")

preds2 <- predict(mod2, hs)
obs2 <- hs$Sat
results2 <- PostFitGOFTest(obs2,preds2)
results2

plot(results2$pear.res~results2$centers)
```
