curve(expr = predict(object = mod.fit, newdata = data.frame(distance = x), type = "response"), col = "black", add = TRUE,
xlim = c(18, 66))
curve(expr = ci.pi(newdata = data.frame(distance = x), mod.fit.obj = mod.fit, alpha = 0.05)$lower, col = "black",
lty = "dotdash", add = TRUE, xlim = c(18, 66))
curve(expr = ci.pi(newdata = data.frame(distance = x), mod.fit.obj = mod.fit, alpha = 0.05)$upper, col = "black",
lty = "dotdash", add = TRUE, xlim = c(18, 66))
legend(x = 20, y = 0.4, legend = c("Logistic regression model", "95% individual C.I."), lty = c("solid", "dotdash"), col = c("black", "black"), bty = "n")
# dev.off()  # Create plot for book
head(w.n[rev(order(n$good)),]) # This shows that 789 observations are at distance of 20 yards
# but the next largest is only 30, which is at a distance of 32 yards
# Possible points of concern?
w.n.subset<-w.n[w.n$distance == 32 | w.n$distance == 43 | w.n$distance == 46 | w.n$distance == 51,]  # "|" means "or"
predict.data<-data.frame(distance=c(32, 43, 46, 51))
pi.hat<-predict(object = mod.fit, newdata = predict.data, type = "response")
data.frame(w.n.subset, pi.hat)
########################
# profile LR ratio version of the plot
# Easiest way - add the bands to the previous plot
#  Notice the bands are practically the same as those from the Wald intervals
distances<-18:66
K<-cbind(1, distances)
class(K)  # matrix
head(K)
linear.combo<-mcprofile(object = mod.fit, CM = K)  # Calculate -2log(Lambda)
ci.logit.profile<-confint(object = linear.combo, level = 0.95, adjust = "none")  # CI for beta_0 + beta_1 * x
ci.logit.profile
profile.lr.int<-exp(ci.logit.profile$confint)/(1 + exp(ci.logit.profile$confint))
# Add bands
lines(x = distances, y = profile.lr.int[,1], col = "green")
lines(x = distances, y = profile.lr.int[,2], col = "green")
# Another way to do the sample type of plot using a new ci.pi()-like function
ci.pi2<-function(x, mod.fit.obj, alpha){
K<-cbind(1, x)
linear.combo<-mcprofile(object = mod.fit, CM = K)
ci.logit.profile<-confint(object = linear.combo, level = 1 - alpha, adjust = "none")
profile.lr.int<-exp(ci.logit.profile$confint)/(1 + exp(ci.logit.profile$confint))
list(lower = profile.lr.int[,1], upper = profile.lr.int[,2])
}
# Test case
ci.pi2(x = 20, mod.fit.obj = mod.fit, alpha = 0.05)
x11(width = 7, height = 6, pointsize = 12)
symbols(x = w$distance, y = w$good/n$good, circles = sqrt(n$good), inches = 0.5, xlab = "Distance (yards)", ylab = "Estimated probability",
panel.first = grid(col = "gray", lty = "dotted"))
# Put estimated logistic regression model on the plot
curve(expr = predict(object = mod.fit, newdata = data.frame(distance = x), type = "response"), col = "red", add = TRUE,
xlim = c(18, 66))
# Plot C.I. bands
curve(expr = ci.pi2(x = x, mod.fit.obj = mod.fit, alpha = 0.05)$lower, col = "blue",
lty = "dotdash", add = TRUE, xlim = c(18, 66))
curve(expr = ci.pi2(x = x, mod.fit.obj = mod.fit, alpha = 0.05)$upper, col = "blue",
lty = "dotdash", add = TRUE, xlim = c(18, 66))
# Legend
legend(locator(1), legend = c("Logistic regression model", "95% individual C.I."), lty = c("solid", "dotdash"), col = c("red", "blue"), bty = "n")
#####################################################################
# Transformations
mod.fit.Ho<-glm(formula = good ~ distance + wind, family = binomial(link = logit), data = placekick)
mod.fit.Ha<-glm(formula = good ~ distance + wind + distance:wind, family = binomial(link = logit), data = placekick)
summary(mod.fit.Ha)
anova(mod.fit.Ho, mod.fit.Ha, test = "Chisq")
library(package = car)  # Would need this if it has not already been used.
Anova(mod.fit.Ha, test = "LR")  # Simpler way for the test
Anova(mod.fit.Ho, test = "LR")  # Notice that the test statistics match the first two given in Anova(mod.fit.Ha, test = "LR")
# This helps to demonstrate that the "distance:wind" interaction would not be present in the test for distance (or wind)
#################################################
# OR for wind at a specific distance
beta.hat<-mod.fit.Ha$coefficients[2:4]  # Pull out beta^_1, beta^_2, beta^_3 so that we are using the same index as subscripts in the model (helpful to reduce coding errors)
# Could also use  mod.fit.Ha$coefficients[-1]
c<-1
distance<-seq(from = 20, to = 60, by = 10)  # Examine distances 20 to 60 by 10 yard increments
OR.wind<-exp(c*(beta.hat[2] + beta.hat[3]*distance))  # Estimated OR
cov.mat<-vcov(mod.fit.Ha)[2:4,2:4]  # Pull out covariance matrix for beta^_1, beta^_2, beta^_3
var.log.OR<-cov.mat[2,2] + distance^2*cov.mat[3,3] + 2*distance*cov.mat[2,3]   # Var(beta^_2 + distance*beta^_3)
ci.log.OR.low<-c*(beta.hat[2] + beta.hat[3]*distance) - c*qnorm(p = 0.975)*sqrt(var.log.OR)  # Will not work correctly if use qnorm(p = c(0.025, 0.975)) due to multiple vectors being used
ci.log.OR.up<-c*(beta.hat[2] + beta.hat[3]*distance) + c*qnorm(p = 0.975)*sqrt(var.log.OR)
data.frame(OR.wind, OR.low = exp(ci.log.OR.low), OR.up = exp(ci.log.OR.up))
round(data.frame(distance = distance, OR.hat = 1/OR.wind, OR.low = 1/exp(ci.log.OR.up), OR.up = 1/exp(ci.log.OR.low)),2)  #Inverted
#################################################
# OR for distance at a specific wind
c<-10   # 10-yard increment
wind<-0:1  # Examine wind for 0 and 1
OR.dist<-exp(c*(beta.hat[1] + beta.hat[3]*wind))  # Estimated OR
cov.mat<-vcov(mod.fit.Ha)[2:4,2:4]  # Pull out covariance matrix for beta^_1, beta^_2, beta^_3
var.log.OR<-cov.mat[1,1] + wind^2*cov.mat[3,3] + 2*wind*cov.mat[1,3]   # Var(beta^_2 + distance*beta^_3)
ci.log.OR.low<-c*(beta.hat[1] + beta.hat[3]*wind) - c*qnorm(p = 0.975)*sqrt(var.log.OR)  # Will not work correctly if use qnorm(p = c(0.025, 0.975)) due to multiple vectors being used
ci.log.OR.up<-c*(beta.hat[1] + beta.hat[3]*wind) + c*qnorm(p = 0.975)*sqrt(var.log.OR)
data.frame(OR.dist, OR.low = exp(ci.log.OR.low), OR.up = exp(ci.log.OR.up))
round(data.frame(wind = wind, OR.hat = 1/OR.dist, OR.low = 1/exp(ci.log.OR.up), OR.up = 1/exp(ci.log.OR.low)),2)  #Inverted
#################################################
# Profile LR intervals using mcprofile package
library(package = mcprofile)   # Need if had not already been used
K<-matrix(data = c(0, 0, 1, 20,
0, 0, 1, 30,
0, 0, 1, 40,
0, 0, 1, 50,
0, 0, 1, 60), nrow = 5, ncol = 4, byrow = TRUE)
# A little quicker way to form K
# distance<-seq(from = 20, to = 60, by = 10)
# K<-cbind(0, 0, 1, distance)
K
# profile LR
linear.combo<-mcprofile(object = mod.fit.Ha, CM = K)
ci.log.OR<-confint(object = linear.combo, level = 0.95, adjust = "none")
# ci.log.OR
data.frame(distance, OR.hat = round(1/exp(ci.log.OR$estimate), 2),
OR.low = round(1/exp(ci.log.OR$confint$upper), 2),
OR.up = round(1/exp(ci.log.OR$confint$lower), 2))
# Wald
save.wald<-wald(object = linear.combo)
ci.log.OR.wald<-confint(object = save.wald, level = 0.95, adjust = "none")
data.frame(distance, OR.hat = round(1/exp(ci.log.OR.wald$estimate), 2),
OR.low = round(1/exp(ci.log.OR.wald$confint$upper), 2),
OR.up = round(1/exp(ci.log.OR.wald$confint$lower), 2))
# OR for 10 yard decrease in distance holding wind constant at 0 or 1
K<-matrix(data = c(0, -10, 0, 0,
0, -10, 0, -10), nrow = 2, ncol = 4, byrow = TRUE)
K
# profile LR
linear.combo<-mcprofile(object = mod.fit.Ha, CM = K)
ci.log.OR<-confint(object = linear.combo, level = 0.95, adjust = "none")
exp(ci.log.OR)
# Wald
save.wald<-wald(object = linear.combo)
ci.log.OR.wald<-confint(object = save.wald, level = 0.95, adjust = "none")
exp(ci.log.OR.wald)
#################################################
# Equivalent ways to estimate good ~ distance + wind + distance:wind
mod.fit.dw2<-glm(formula = good ~ distance*wind, family = binomial(link = logit), data = placekick)
summary(mod.fit.dw2)
mod.fit.dw3<-glm(formula = good ~ (distance + wind)^2, family = binomial(link = logit), data = placekick)
summary(mod.fit.dw3)
#################################################
# Plot
x11(width = 10, height = 6, pointsize = 12)
# pdf(file = "c:\\figures\\Figure2.6color.pdf", width = 7, height = 6, colormodel = "cmyk")   # Create plot for book
par(mfrow = c(1,2))
curve(expr = predict(object = mod.fit.Ho, newdata = data.frame(distance = x, wind = 0), type = "response"), col = "red", lty = "solid", xlim = c(20,60),
ylim = c(0,1), ylab = "Estimated probability", main = "Without interaction",
xlab = "Distance", panel.first = grid(col = "gray", lty = "dotted"), cex.main = 0.9, lwd = 1)
curve(expr = predict(object = mod.fit.Ho, newdata = data.frame(distance = x, wind = 1), type = "response"),
col = "blue", lty = "dotdash", lwd = 1, add = TRUE)
legend(x = 20, y = 0.4, legend = c("Wind = 0", "Wind = 1"), lty = c("solid", "dotdash"), col = c("red", "blue"),
lwd = c(1,1), bty = "n")
curve(expr = predict(object = mod.fit.Ha, newdata = data.frame(distance = x, wind = 0), type = "response"), col = "red", lty = "solid", xlim = c(20,60),
ylim = c(0,1), ylab = "Estimated probability", main = "With interaction",
xlab = "Distance", panel.first = grid(col = "gray", lty = "dotted"), cex.main = 0.9, lwd = 1)
curve(expr = predict(object = mod.fit.Ha, newdata = data.frame(distance = x, wind = 1), type = "response"),
col = "blue", lty = "dotdash", lwd = 1, add = TRUE)
legend(x = 20, y = 0.4, legend = c("Wind = 0", "Wind = 1"), lty = c("solid", "dotdash"), col = c("red", "blue"),
lwd = c(1,1), bty = "n")
# Old plot title: expression(logit(hat(pi)) == hat(beta)[0] + hat(beta)[1]*distance + hat(beta)[2]*wind + hat(beta)[3]*distance%*%wind)
# dev.off()  # Create plot for book
# Black-and-white version of plot
# pdf(file = "c:\\figures\\Figure2.6BW.pdf", width = 7, height = 6, colormodel = "cmyk")   # Create plot for book
par(mfrow = c(1,2))
curve(expr = predict(object = mod.fit.Ho, newdata = data.frame(distance = x, wind = 0), type = "response"), col = "black", lty = "solid", xlim = c(20,60),
ylim = c(0,1), ylab = "Estimated probability", main = "Without interaction",
xlab = "Distance", cex.main = 0.9, lwd = 1)
curve(expr = predict(object = mod.fit.Ho, newdata = data.frame(distance = x, wind = 1), type = "response"),
col = "black", lty = "dotdash", lwd = 1, add = TRUE)
legend(x = 20, y = 0.4, legend = c("Wind = 0", "Wind = 1"), lty = c("solid", "dotdash"), col = c("black", "black"),
lwd = c(1,1), bty = "n")
curve(expr = predict(object = mod.fit.Ha, newdata = data.frame(distance = x, wind = 0), type = "response"), col = "black", lty = "solid", xlim = c(20,60),
ylim = c(0,1), ylab = "Estimated probability", main = "With interaction",
xlab = "Distance", cex.main = 0.9, lwd = 1)
curve(expr = predict(object = mod.fit.Ha, newdata = data.frame(distance = x, wind = 1), type = "response"),
col = "black", lty = "dotdash", lwd = 1, add = TRUE)
legend(x = 20, y = 0.4, legend = c("Wind = 0", "Wind = 1"), lty = c("solid", "dotdash"), col = c("black", "black"),
lwd = c(1,1), bty = "n")
# dev.off()  # Create plot for book
#####################################################################
# Estimate the model using the convergence arguments
mod.fit<-glm(formula = good ~ distance, family = binomial(link = logit), data = placekick, trace = TRUE, epsilon = 0.0001, maxit = 50)
# names(mod.fit)
mod.fit$control
mod.fit$converged
mod.fit$coefficients
# Check convergence
abs(775.745-775.7451)/(0.1 + abs(775.745))
abs(775.7451-775.8357)/(0.1 + abs(775.7451))
# 3 iterations only to show non-convergence
mod.fit.noconv<-glm(formula = good ~ distance, family = binomial(link = logit), data = placekick, trace = TRUE, epsilon = 0.0001, maxit = 3)
mod.fit.noconv$coefficients
#####################################################################
# Estimate the logistic, probit, and complementary log-log models
# Logistic
mod.fit.logit<-glm(formula = good ~ distance, family = binomial(link = logit), data = placekick)
round(summary(mod.fit.logit)$coefficients, 4)
# Probit
mod.fit.probit<-glm(formula = good ~ distance, family = binomial(link = probit), data = placekick)
round(summary(mod.fit.probit)$coefficients, 4)
# Complementary log-log
mod.fit.cloglog<-glm(formula = good ~ distance, family = binomial(link = cloglog), data = placekick)
round(summary(mod.fit.cloglog)$coefficients, 4)
# Compare pi^ values without predict()
distance<-c(20, 35, 50)
plogis(q = mod.fit.logit$coefficients[1] + mod.fit.logit$coefficients[2]*distance)  # Logistic
pnorm(q = mod.fit.probit$coefficients[1] + mod.fit.probit$coefficients[2]*distance)  # Probit
1-exp(-exp(mod.fit.cloglog$coefficients[1] + mod.fit.cloglog$coefficients[2]*distance))  # Complementary log-log
# Compare pi^ values with predict() (easier)
predict.data<-data.frame(distance = c(20, 35, 50))
logistic.pi<-predict(object = mod.fit.logit, newdata = predict.data, type = "response")
probit.pi<-predict(object = mod.fit.probit, newdata = predict.data, type = "response")
cloglog.pi<-predict(object = mod.fit.cloglog, newdata = predict.data, type = "response")
round(data.frame(predict.data, logistic.pi, probit.pi, cloglog.pi),4)
# For distance = 20 example and probit model
lin.pred<-as.numeric(mod.fit.probit$coefficients[1] + mod.fit.probit$coefficients[2]*20)
lin.pred
pnorm(q = lin.pred)
pnorm(q = 1.951195)
###################
# Bubble plot - Much of the same code from before is included here
w<-aggregate(formula = good ~ distance, data = placekick, FUN = sum)
n<-aggregate(formula = good ~ distance, data = placekick, FUN = length)
w.n<-data.frame(distance = w$distance, success = w$good, trials = n$good, proportion = round(w$good/n$good,4))
# Plot of the observed proportions with logistic regression model
x11(width = 7, height = 6, pointsize = 12)
# pdf(file = "c:\\figures\\Figure2.14color.pdf", width = 7, height = 6, colormodel = "cmyk")   # Create plot for book
symbols(x = w$distance, y = w$good/n$good, circles = sqrt(n$good), inches = 0.5, xlab="Distance (yards)", ylab="Estimated probability",
panel.first = grid(col = "gray", lty = "dotted"))
# Estimated logistic regression model
curve(expr = predict(object = mod.fit.logit, newdata = data.frame(distance = x), type = "response"),
col = "red", lwd = 2, add = TRUE, lty = 1, xlim = c(18,66))
# Estimated probit model
curve(expr = predict(object = mod.fit.probit, newdata = data.frame(distance = x), type = "response"),
col = "blue", lwd = 2, add = TRUE, lty = 2, xlim = c(18,66))
# Estimated complementary log-log model
curve(expr = predict(object = mod.fit.cloglog, newdata = data.frame(distance = x), type = "response"),
col = "green", lwd = 2, add = TRUE, lty = 4, xlim = c(18,66))
# Legend
legend(x = 18, y = 0.42, legend = c("Logistic", "Probit", "Complementary log-log"), lty = c(1, 2, 4), lwd = c(2,2,2),
bty = "n", col=c("red", "blue", "green"), cex = 1)
# dev.off()  # Create plot for book
# Black-and-white version of plot
# pdf(file = "c:\\figures\\Figure2.14BW.pdf", width = 7, height = 6, colormodel = "cmyk")   # Create plot for book
symbols(x = w$distance, y = w$good/n$good, circles = sqrt(n$good), inches = 0.5, xlab="Distance (yards)", ylab="Estimated probability")
curve(expr = predict(object = mod.fit.logit, newdata = data.frame(distance = x), type = "response"),
col = "black", lwd = 2, add = TRUE, lty = 1, xlim = c(18,66))
curve(expr = predict(object = mod.fit.probit, newdata = data.frame(distance = x), type = "response"),
col = "black", lwd = 2, add = TRUE, lty = 2, xlim = c(18,66))
curve(expr = predict(object = mod.fit.cloglog, newdata = data.frame(distance = x), type = "response"),
col = "black", lwd = 2, add = TRUE, lty = 4, xlim = c(18,66))
legend(x = 18, y = 0.42, legend = c("Logistic", "Probit", "Complementary log-log"), lty = c(1, 2, 4), lwd = c(2,2,2),
bty = "n", col=c("black", "black", "black"), cex = 1)
# dev.off()  # Create plot for book
###################
# ORs
pi.hat<-data.frame(predict.data, logistic.pi, probit.pi, cloglog.pi)
odds.x20<-pi.hat[1, 2:4]/(1 - pi.hat[1, 2:4])
odds.x35<-pi.hat[2, 2:4]/(1 - pi.hat[2, 2:4])
odds.x50<-pi.hat[3, 2:4]/(1 - pi.hat[3, 2:4])
OR.20.35<-odds.x20/odds.x35
OR.35.50<-odds.x35/odds.x50
data.frame(OR = c("20 vs. 35", "35 vs. 50"), round(rbind(OR.20.35, OR.35.50),2) )
expit(1/(1 + exp(-ci.logit.profile$confint)))  # Another way to perform transformation
expit(1/(1 + exp(-ci.logit.profile$confint)))  # Another way to perform transformation
1/(1 + exp(-ci.logit.profile$confint))  # Another way to perform transformation
expit(1 + exp(-ci.logit.profile$confint))  # Another way to perform transformation
x11(width = 7, height = 6, pointsize = 12)
symbols(x = w$distance, y = w$good/n$good, circles = sqrt(n$good), inches = 0.5, xlab = "Distance (yards)", ylab = "Estimated probability",
panel.first = grid(col = "gray", lty = "dotted"))
curve(expr = predict(object = mod.fit, newdata = data.frame(distance = x), type = "response"), col = "red", add = TRUE,
xlim = c(18, 66))
curve(expr = ci.pi(newdata = data.frame(distance = x), mod.fit.obj = mod.fit, alpha = 0.05)$lower, col = "blue",
lty = "dotdash", add = TRUE, xlim = c(18, 66))
curve(expr = ci.pi(newdata = data.frame(distance = x), mod.fit.obj = mod.fit, alpha = 0.05)$upper, col = "blue",
lty = "dotdash", add = TRUE, xlim = c(18, 66))
legend(x = 20, y = 0.4, legend = c("Logistic regression model", "95% individual C.I."), lty = c("solid", "dotdash"), col = c("red", "blue"), bty = "n")
symbols(x = w$distance, y = w$good/n$good, circles = sqrt(n$good), inches = 0.5, xlab = "Distance (yards)", ylab = "Estimated probability")
curve(expr = predict(object = mod.fit, newdata = data.frame(distance = x), type = "response"), col = "black", add = TRUE,
xlim = c(18, 66))
curve(expr = ci.pi(newdata = data.frame(distance = x), mod.fit.obj = mod.fit, alpha = 0.05)$lower, col = "black",
lty = "dotdash", add = TRUE, xlim = c(18, 66))
curve(expr = ci.pi(newdata = data.frame(distance = x), mod.fit.obj = mod.fit, alpha = 0.05)$upper, col = "black",
lty = "dotdash", add = TRUE, xlim = c(18, 66))
legend(x = 20, y = 0.4, legend = c("Logistic regression model", "95% individual C.I."), lty = c("solid", "dotdash"), col = c("black", "black"), bty = "n")
head(w.n[rev(order(n$good)),]) # This shows that 789 observations are at distance of 20 yards
w.n.subset<-w.n[w.n$distance == 32 | w.n$distance == 43 | w.n$distance == 46 | w.n$distance == 51,]  # "|" means "or"
distances<-18:66
K<-cbind(1, distances)
class(K)  # matrix
head(K)
linear.combo<-mcprofile(object = mod.fit, CM = K)  # Calculate -2log(Lambda)
ci.logit.profile<-confint(object = linear.combo, level = 0.95, adjust = "none")  # CI for beta_0 + beta_1 * x
ci.logit.profile
profile.lr.int<-exp(ci.logit.profile$confint)/(1 + exp(ci.logit.profile$confint))
distances<-18:66
K<-cbind(1, distances)
class(K)  # matrix
head(K)
linear.combo<-mcprofile(object = mod.fit, CM = K)  # Calculate -2log(Lambda)
ci.logit.profile<-confint(object = linear.combo, level = 0.95, adjust = "none")  # CI for beta_0 + beta_1 * x
ci.logit.profile
profile.lr.int<-exp(ci.logit.profile$confint)/(1 + exp(ci.logit.profile$confint))
lines(x = distances, y = profile.lr.int[,1], col = "green")
x11(width = 7, height = 6, pointsize = 12)
symbols(x = w$distance, y = w$good/n$good, circles = sqrt(n$good), inches = 0.5, xlab = "Distance (yards)", ylab = "Estimated probability",
panel.first = grid(col = "gray", lty = "dotted"))
curve(expr = predict(object = mod.fit, newdata = data.frame(distance = x), type = "response"), col = "red", add = TRUE,
xlim = c(18, 66))
curve(expr = ci.pi(newdata = data.frame(distance = x), mod.fit.obj = mod.fit, alpha = 0.05)$lower, col = "blue",
lty = "dotdash", add = TRUE, xlim = c(18, 66))
curve(expr = ci.pi(newdata = data.frame(distance = x), mod.fit.obj = mod.fit, alpha = 0.05)$upper, col = "blue",
lty = "dotdash", add = TRUE, xlim = c(18, 66))
legend(x = 20, y = 0.4, legend = c("Logistic regression model", "95% individual C.I."), lty = c("solid", "dotdash"), col = c("red", "blue"), bty = "n")
symbols(x = w$distance, y = w$good/n$good, circles = sqrt(n$good), inches = 0.5, xlab = "Distance (yards)", ylab = "Estimated probability")
curve(expr = predict(object = mod.fit, newdata = data.frame(distance = x), type = "response"), col = "black", add = TRUE,
xlim = c(18, 66))
curve(expr = ci.pi(newdata = data.frame(distance = x), mod.fit.obj = mod.fit, alpha = 0.05)$lower, col = "black",
lty = "dotdash", add = TRUE, xlim = c(18, 66))
curve(expr = ci.pi(newdata = data.frame(distance = x), mod.fit.obj = mod.fit, alpha = 0.05)$upper, col = "black",
lty = "dotdash", add = TRUE, xlim = c(18, 66))
legend(x = 20, y = 0.4, legend = c("Logistic regression model", "95% individual C.I."), lty = c("solid", "dotdash"), col = c("black", "black"), bty = "n")
head(w.n[rev(order(n$good)),]) # This shows that 789 observations are at distance of 20 yards
w.n.subset<-w.n[w.n$distance == 32 | w.n$distance == 43 | w.n$distance == 46 | w.n$distance == 51,]  # "|" means "or"
predict.data<-data.frame(distance=c(32, 43, 46, 51))
pi.hat<-predict(object = mod.fit, newdata = predict.data, type = "response")
data.frame(w.n.subset, pi.hat)
distances<-18:66
K<-cbind(1, distances)
class(K)  # matrix
head(K)
linear.combo<-mcprofile(object = mod.fit, CM = K)  # Calculate -2log(Lambda)
ci.logit.profile<-confint(object = linear.combo, level = 0.95, adjust = "none")  # CI for beta_0 + beta_1 * x
ci.logit.profile
profile.lr.int<-exp(ci.logit.profile$confint)/(1 + exp(ci.logit.profile$confint))
lines(x = distances, y = profile.lr.int[,1], col = "green")
lines(x = distances, y = profile.lr.int[,2], col = "green")
View(profile.lr.int)
mod.fit.Ho<-glm(formula = good ~ distance + wind, family = binomial(link = logit), data = placekick)
mod.fit.Ha<-glm(formula = good ~ distance + wind + distance:wind, family = binomial(link = logit), data = placekick)
summary(mod.fit.Ha)
anova(mod.fit.Ho, mod.fit.Ha, test = "Chisq")
library(package = car)  # Would need this if it has not already been used.
Anova(mod.fit.Ha, test = "LR")  # Simpler way for the test
Anova(mod.fit.Ho, test = "LR")  # Notice that the test statistics match the first two given in Anova(mod.fit.Ha, test = "LR")
beta.hat<-mod.fit.Ha$coefficients[2:4]  # Pull out beta^_1, beta^_2, beta^_3 so that we are using the same index as subscripts in the model (helpful to reduce coding errors)
beta.hat<-mod.fit.Ha$coefficients[2:4]  # Pull out beta^_1, beta^_2, beta^_3 so that we are using the same index as subscripts in the model (helpful to reduce coding errors)
c<-1
distance<-seq(from = 20, to = 60, by = 10)  # Examine distances 20 to 60 by 10 yard increments
OR.wind<-exp(c*(beta.hat[2] + beta.hat[3]*distance))  # Estimated OR
cov.mat<-vcov(mod.fit.Ha)[2:4,2:4]  # Pull out covariance matrix for beta^_1, beta^_2, beta^_3
var.log.OR<-cov.mat[2,2] + distance^2*cov.mat[3,3] + 2*distance*cov.mat[2,3]   # Var(beta^_2 + distance*beta^_3)
ci.log.OR.low<-c*(beta.hat[2] + beta.hat[3]*distance) - c*qnorm(p = 0.975)*sqrt(var.log.OR)  # Will not work correctly if use qnorm(p = c(0.025, 0.975)) due to multiple vectors being used
ci.log.OR.up<-c*(beta.hat[2] + beta.hat[3]*distance) + c*qnorm(p = 0.975)*sqrt(var.log.OR)
data.frame(OR.wind, OR.low = exp(ci.log.OR.low), OR.up = exp(ci.log.OR.up))
round(data.frame(distance = distance, OR.hat = 1/OR.wind, OR.low = 1/exp(ci.log.OR.up), OR.up = 1/exp(ci.log.OR.low)),2)  #Inverted
c<-10   # 10-yard increment
wind<-0:1  # Examine wind for 0 and 1
OR.dist<-exp(c*(beta.hat[1] + beta.hat[3]*wind))  # Estimated OR
cov.mat<-vcov(mod.fit.Ha)[2:4,2:4]  # Pull out covariance matrix for beta^_1, beta^_2, beta^_3
var.log.OR<-cov.mat[1,1] + wind^2*cov.mat[3,3] + 2*wind*cov.mat[1,3]   # Var(beta^_2 + distance*beta^_3)
ci.log.OR.low<-c*(beta.hat[1] + beta.hat[3]*wind) - c*qnorm(p = 0.975)*sqrt(var.log.OR)  # Will not work correctly if use qnorm(p = c(0.025, 0.975)) due to multiple vectors being used
ci.log.OR.up<-c*(beta.hat[1] + beta.hat[3]*wind) + c*qnorm(p = 0.975)*sqrt(var.log.OR)
data.frame(OR.dist, OR.low = exp(ci.log.OR.low), OR.up = exp(ci.log.OR.up))
round(data.frame(wind = wind, OR.hat = 1/OR.dist, OR.low = 1/exp(ci.log.OR.up), OR.up = 1/exp(ci.log.OR.low)),2)  #Inverted
library(package = mcprofile)   # Need if had not already been used
K<-matrix(data = c(0, 0, 1, 20,
0, 0, 1, 30,
0, 0, 1, 40,
0, 0, 1, 50,
0, 0, 1, 60), nrow = 5, ncol = 4, byrow = TRUE)
K
linear.combo<-mcprofile(object = mod.fit.Ha, CM = K)
ci.log.OR<-confint(object = linear.combo, level = 0.95, adjust = "none")
ci.log.OR
data.frame(distance, OR.hat = round(1/exp(ci.log.OR$estimate), 2),
OR.low = round(1/exp(ci.log.OR$confint$upper), 2),
OR.up = round(1/exp(ci.log.OR$confint$lower), 2))
save.wald<-wald(object = linear.combo)
ci.log.OR.wald<-confint(object = save.wald, level = 0.95, adjust = "none")
data.frame(distance, OR.hat = round(1/exp(ci.log.OR.wald$estimate), 2),
OR.low = round(1/exp(ci.log.OR.wald$confint$upper), 2),
OR.up = round(1/exp(ci.log.OR.wald$confint$lower), 2))
K<-matrix(data = c(0, -10, 0, 0,
0, -10, 0, -10), nrow = 2, ncol = 4, byrow = TRUE)
K
linear.combo<-mcprofile(object = mod.fit.Ha, CM = K)
ci.log.OR<-confint(object = linear.combo, level = 0.95, adjust = "none")
exp(ci.log.OR)
K<-matrix(data = c(0, -10, 0, 0,
0, -10, 1, -10), nrow = 2, ncol = 4, byrow = TRUE)
K
linear.combo<-mcprofile(object = mod.fit.Ha, CM = K)
ci.log.OR<-confint(object = linear.combo, level = 0.95, adjust = "none")
exp(ci.log.OR)
K<-matrix(data = c(0, -10, 0, 0,
0, -10, 0, -10), nrow = 2, ncol = 4, byrow = TRUE)
K
linear.combo<-mcprofile(object = mod.fit.Ha, CM = K)
ci.log.OR<-confint(object = linear.combo, level = 0.95, adjust = "none")
exp(ci.log.OR)
save.wald<-wald(object = linear.combo)
ci.log.OR.wald<-confint(object = save.wald, level = 0.95, adjust = "none")
exp(ci.log.OR.wald)
mod.fit.Ha$coefficients
getwd()
setwd('/Users/winlin/Desktop/w271-time-series/programs/Chapter2/')
dir
list.files
list.files()
file.edit('TomatoVirus.R')
tomato <- read.csv(file  = "/Users/winlin/Desktop/w271-time-series/programs/Chapter2/TomatoVirus.csv")
head(tomato)
tomato
class(tomato$Control)
levels(tomato$Control)
contrasts(tomato$Control)
class(tomato$Infest)
levels(tomato$Infest)
class(factor(tomato$Infest))
levels(factor(tomato$Infest))
contrasts(factor(tomato$Infest))
tomato$Infest<-factor(tomato$Infest)
head(tomato)
class(tomato$Infest)
temp<-factor(tomato$Control, levels = c("C", "B", "N"))  # Change ordering of levels like relevel()
levels(temp)
temp2<-factor(tomato$Control, labels = c("B1", "C1", "N1"))  # Change names of levels
levels(temp2)
mod.fit<-glm(formula = Virus8/Plants ~ Infest + Control, family = binomial(link = logit), data = tomato,
weights = Plants)
summary(mod.fit)
mod.fit$xlevels  # Another way to see the levels of categorical explanatory variables
mod.fit.inter<-glm(formula = Virus8/Plants ~ Infest + Control + Infest:Control, family = binomial(link = logit), data = tomato,
weights = Plants)
summary(mod.fit.inter)
library(package = car)
Anova(mod.fit.inter)
exp(mod.fit$coefficients[2])
1/exp(mod.fit$coefficients[2])
exp(confint.default(object = mod.fit, parm = "Infest2", level = 0.95))
exp(confint(object = mod.fit, parm = "Infest2", level = 0.95))
exp(mod.fit$coefficients[3:4])
exp(confint.default(object = mod.fit, parm = c("ControlC", "ControlN"), level = 0.95))
exp(confint(object = mod.fit, parm = c("ControlC", "ControlN"), level = 0.95))
beta.hat<-mod.fit$coefficients[-1]  # Matches up beta indices with [i] to help avoid mistakes
exp(beta.hat[3] -  beta.hat[2])
cov.mat<-vcov(mod.fit)[2:4,2:4]
var.N.C<-cov.mat[3,3] + cov.mat[2,2] - 2*cov.mat[3,2]
CI.betas<- beta.hat[3]- beta.hat[2] + qnorm(p = c(0.025, 0.975))*sqrt(var.N.C)
exp(CI.betas)
tomato$Control.reorder<-relevel(x = tomato$Control, ref = "C")
mod.fit2<-glm(formula = Virus8/Plants ~ Infest + Control.reorder, family = binomial(link = logit), data = tomato,
weight = Plants)
mod.fit2$coefficients
exp(confint.default(object = mod.fit2, parm = c("Control.reorderB", "Control.reorderN"), level = 0.95))
exp(confint(object = mod.fit2, parm = c("Control.reorderB", "Control.reorderN"), level = 0.95))
library(package = mcprofile)
K<-matrix(data = c(0, 0,  1,  0,
0, 0,  0,  1),  nrow = 2, ncol = 4, byrow = TRUE)
linear.combo<-mcprofile(object = mod.fit, CM = K)
ci.log.OR<-confint(object = linear.combo, level = 0.95, adjust = "none")
ci.log.OR
comparison<-c("C vs. B", "N vs. B")
data.frame(comparison, OR = exp(ci.log.OR$confint))  # These match previous results
K<-matrix(data = c(0, 0, -1,  1),  nrow = 1, ncol = 4, byrow = TRUE)
linear.combo<-mcprofile(object = mod.fit, CM = K)
ci.log.OR<-confint(object = linear.combo, level = 0.95, adjust = "none")
ci.log.OR
data.frame(comparison = "N vs. C", OR = exp(ci.log.OR$confint))  # These match previous results
save.wald<-wald(object = linear.combo)
ci.logit.wald<-confint(object = save.wald, level = 0.95, adjust = "none")
data.frame(lower = exp(ci.logit.wald$confint[,1]), upper = exp(ci.logit.wald$confint[,2]))  # These match previous results
beta.hat<-mod.fit.inter$coefficients[-1]
N.B.Infest2.0<-exp(beta.hat[3])
N.B.Infest2.1<-exp(beta.hat[3] + beta.hat[5])
C.B.Infest2.0<-exp(beta.hat[2])
C.B.Infest2.1<-exp(beta.hat[2] + beta.hat[4])
N.C.Infest2.0<-exp(beta.hat[3] - beta.hat[2])
N.C.Infest2.1<-exp(beta.hat[3] - beta.hat[2] + beta.hat[5] - beta.hat[4])
comparison<-c("N vs. B", "N vs. B", "C vs. B", "C vs. B", "N vs. C", "N vs. C")
data.frame(Infest2 = c(0, 1, 0, 1, 0, 1),
Control = comparison,
OR.hat = round(c(N.B.Infest2.0, N.B.Infest2.1, C.B.Infest2.0, C.B.Infest2.1,
N.C.Infest2.0, N.C.Infest2.1),2))
K<-matrix(data = c(0, 0,  0,  1,  0,  0,
0, 0,  0,  1,  0,  1,
0, 0,  1,  0,  0,  0,
0, 0,  1,  0,  1,  0,
0, 0, -1,  1,  0,  0,
0, 0, -1,  1, -1,  1),  nrow = 6, ncol = 6, byrow = TRUE)
linear.combo<-mcprofile(object = mod.fit.inter, CM = K)
ci.log.OR<-confint(object = linear.combo, level = 0.95, adjust = "none")
ci.log.OR
data.frame(Infest2 = c(0, 1, 0, 1, 0, 1), comparison, OR = round(exp(ci.log.OR$estimate),2),
OR.CI = round(exp(ci.log.OR$confint),2))
ci.log.bon<-confint(object = linear.combo, level = 0.95, adjust = "bonferroni")
ci.log.bon<-confint(object = linear.combo, level = 0.95, adjust = "bonferroni")
ci.log.ss<-confint(object = linear.combo, level = 0.95, adjust = "single-step")
data.frame(Infest2 = c(0, 1, 0, 1, 0, 1), comparison, bon = round(exp(ci.log.bon$confint),2), ss = round(exp(ci.log.ss$confint),2))
save.wald<-wald(object = linear.combo)
ci.logit.wald<-confint(object = save.wald, level = 0.95, adjust = "none")
data.frame(Infest2 = c(0, 1, 0, 1, 0, 1), comparison, OR = round(exp(ci.log.OR$estimate),2),
lower = round(exp(ci.logit.wald$confint[,1]),2), upper = round(exp(ci.logit.wald$confint[,2]),2))
ci.wald.bon<-confint(object = save.wald, level = 0.95, adjust = "bonferroni")
ci.wald.ss<-confint(object =save.wald, level = 0.95, adjust = "single-step")
data.frame(Infest2 = c(0, 1, 0, 1, 0, 1), comparison, bon = round(exp(ci.wald.bon$confint),2), ss = round(exp(ci.wald.ss$confint),2))
K<-matrix(data = c(0, 0,  0,  1,  0,  0,
0, 0,  0,  1,  0,  1,
0, 0,  1,  0,  0,  0,
0, 0,  1,  0,  1,  0),  nrow = 4, ncol = 6, byrow = TRUE)   # No warnings
mcprofile(object = mod.fit.inter, CM = K)
file.edit('Placekick.R')
mod.fit<-glm(formula = good ~ distance, family = binomial(link = logit), data = placekick, trace = TRUE, epsilon = 0.0001, maxit = 50)
mod.fit$control
mod.fit$converged
mod.fit$coefficients
abs(775.745-775.7451)/(0.1 + abs(775.745))
abs(775.7451-775.8357)/(0.1 + abs(775.7451))
mod.fit.noconv<-glm(formula = good ~ distance, family = binomial(link = logit), data = placekick, trace = TRUE, epsilon = 0.0001, maxit = 3)
mod.fit.noconv$coefficients
install.packages('logistf')
